{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "# Kueue Knowledge Share Demo\n",
    "In this demo we will demonstrate how Kueue is used within the CodeFlare SDK. \n",
    "\n",
    "### Requirements\n",
    "* RHOAI installed on ROSA Cluster (this should installed KubeRay and Kueue).\n",
    "* Nvidia GPU Operator installed.\n",
    "* Node Feature Discovery Operator installed.\n",
    "* Accelerator profile CR set appropriately for `nvidia.com/gpu`.\n",
    "* Additional relevant CRs for the above (ClusterPolicy etc See GPU doc if needed).\n",
    "* A `p3.2xlarge` machine pool with a node count set to 3 on cluster. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import pieces from codeflare-sdk\n",
    "from codeflare_sdk import Cluster, ClusterConfiguration, TokenAuthentication"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create authentication object for user permissions using oc credentials\n",
    "auth = TokenAuthentication(\n",
    "    token = \"\",\n",
    "    server = \"\",\n",
    "    skip_tls=False\n",
    ")\n",
    "auth.login()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll define a RayCluster using the SDK as normal. Note that we've commented out the local_queue value. By default, the SDK will try to locate the name of your default local queue based on the annotation: `\"kueue.x-k8s.io/default-queue\": \"true\"` unless you specify otherwise.\n",
    "\n",
    "If you don't have the relevant CRs you can create instances using the following:\n",
    "\n",
    "### CRs Required by Kueue\n",
    "___\n",
    "**ClusterQueue CR**\n",
    "```yaml\n",
    "apiVersion: kueue.x-k8s.io/v1beta1\n",
    "kind: ClusterQueue\n",
    "metadata:\n",
    "  name: default\n",
    "spec:\n",
    "  namespaceSelector: {}\n",
    "  resourceGroups:\n",
    "    - coveredResources: [\"cpu\", \"memory\", \"nvidia.com/gpu\"]\n",
    "      flavors:\n",
    "        - name: \"default\"\n",
    "          resources:\n",
    "            - name: \"cpu\"\n",
    "              nominalQuota: 2\n",
    "            - name: \"memory\"\n",
    "              nominalQuota: 32Gi\n",
    "            - name: \"nvidia.com/gpu\"\n",
    "              nominalQuota: 2\n",
    "```\n",
    "___\n",
    "**LocalQueue CR**\n",
    "\n",
    "```yaml\n",
    "apiVersion: kueue.x-k8s.io/v1beta1\n",
    "kind: LocalQueue\n",
    "metadata:\n",
    "  name: default\n",
    "  namespace: my-namespace  # must match the namespace where the job is created\n",
    "  annotations:\n",
    "    kueue.x-k8s.io/default-queue: \"true\"  # Optional: allows the SDK to pick this up as explained above.\n",
    "spec:\n",
    "  clusterQueue: default  # must match the name of your ClusterQueue\n",
    "```\n",
    "___\n",
    "**ResourceFlavor CR**\n",
    "\n",
    "```yaml\n",
    "apiVersion: kueue.x-k8s.io/v1beta1\n",
    "kind: ResourceFlavor\n",
    "metadata:\n",
    "  name: default\n",
    "```\n",
    "___\n",
    "\n",
    "Once these have been created, KubeRay and Kueue (which are both installed on RHOAI by default) will be able to interact. Now that we have the relevant CRs created, let's use the SDK to create a RayCluster. We'll intentionally set our CPU requests above the quota we set above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Create and configure our cluster object\n",
    "# The SDK will try to find the name of your default local queue based on the annotation \"kueue.x-k8s.io/default-queue\": \"true\" unless you specify the local queue manually below\n",
    "cluster_name = \"kueue-ks-raycluster\"\n",
    "cluster1 = Cluster(ClusterConfiguration(\n",
    "    name=cluster_name,\n",
    "    head_cpu_requests=3,  # Requesting 3 CPUs, more than the available 2 CPUs in the ClusterQueue\n",
    "    head_cpu_limits=3,\n",
    "    head_memory_requests=6,\n",
    "    head_memory_limits=6,\n",
    "    head_extended_resource_requests={'nvidia.com/gpu': 1},  # 1 GPU for the head node\n",
    "    worker_extended_resource_requests={'nvidia.com/gpu': 1},  # 1 GPU for each worker node\n",
    "    num_workers=2,\n",
    "    worker_cpu_requests='1',  # Requesting 1 CPU per worker (this adds up to 5 CPUs total)\n",
    "    worker_cpu_limits=1,\n",
    "    worker_memory_requests=4,\n",
    "    worker_memory_limits=6,\n",
    "    write_to_file=False,  # Writing Ray cluster files to disk (optional)\n",
    "    # local_queue=\"kueue-ks\" # Commented out for reasons outlined above\n",
    "))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Click the Cluster Up button to start the RayCluster. Alternatively, run the below cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bring up the cluster\n",
    "cluster1.up()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's check the cluster's status via the below cell. Because we've exceeded our CPU quota defined in our `ClusterQueue`, we should expect an inactive RayCluster with a status of `SUSPENDED`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster1.status()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Verification\n",
    "___\n",
    "\n",
    "* You can verify this by running the command:\n",
    "```\n",
    "oc get localqueue <your-local-queue-name> -n <namespace> -o yaml\n",
    "```\n",
    "\n",
    "* If you check the bottom of the CR, you should see the following:\n",
    "```yaml\n",
    "pendingWorkloads: 1\n",
    "```\n",
    "\n",
    "### Adjusting the Quota\n",
    "___\n",
    "* We can unblock the workload by increasing our `ClusterQueue`. Adjust the CR to match the below values:\n",
    "```yaml\n",
    "apiVersion: kueue.x-k8s.io/v1beta1\n",
    "kind: ClusterQueue\n",
    "metadata:\n",
    "  name: default\n",
    "spec:\n",
    "  resourceGroups:\n",
    "    - coveredResources:\n",
    "        - cpu\n",
    "        - memory\n",
    "        - nvidia.com/gpu\n",
    "      flavors:\n",
    "        - name: default\n",
    "          resources:\n",
    "            - name: cpu\n",
    "              nominalQuota: \"8\"  # Increased CPU quota to unblock the job\n",
    "            - name: memory\n",
    "              nominalQuota: 64Gi  # Increased memory quota\n",
    "            - name: nvidia.com/gpu\n",
    "              nominalQuota: \"4\"  # Increased GPU quota\n",
    "```\n",
    "\n",
    "* Run the above oc command again and this time you should be able to observe similar to the following:\n",
    "```yaml\n",
    "status:\n",
    "  admittedWorkloads: 1\n",
    "  conditions:\n",
    "  - lastTransitionTime: \"2025-04-25T09:03:27Z\"\n",
    "    message: Can admit new workloads\n",
    "    observedGeneration: 3\n",
    "    reason: Ready\n",
    "    status: \"True\"\n",
    "    type: Active\n",
    "  flavorsReservation:\n",
    "  - name: default\n",
    "    resources:\n",
    "    - borrowed: \"0\"\n",
    "      name: cpu\n",
    "      total: \"5\"\n",
    "    - borrowed: \"0\"\n",
    "      name: memory\n",
    "      total: 13671875Ki\n",
    "    - borrowed: \"0\"\n",
    "      name: nvidia.com/gpu\n",
    "      total: \"3\"\n",
    "  flavorsUsage:\n",
    "  - name: default\n",
    "    resources:\n",
    "    - borrowed: \"0\"\n",
    "      name: cpu\n",
    "      total: \"5\"\n",
    "    - borrowed: \"0\"\n",
    "      name: memory\n",
    "      total: 13671875Ki\n",
    "    - borrowed: \"0\"\n",
    "      name: nvidia.com/gpu\n",
    "      total: \"3\"\n",
    "  pendingWorkloads: 0\n",
    "  reservingWorkloads: 1\n",
    "```\n",
    "\n",
    "* Next, we can verify this further by checking the cluster status via the below cell. NOTE: Allow some time for the cluster to be created."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster1.status()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Resource Contention\n",
    "We can further illustrate how Kueue allocates resources by creating an additional RayCluster that will exceed the quota we set.\n",
    "Execute the below cell to create the new RayCluster."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster_name_2 = \"kueue-ks-raycluster-2\"\n",
    "cluster2 = Cluster(ClusterConfiguration(\n",
    "    name=cluster_name_2,\n",
    "    head_cpu_requests=3,\n",
    "    head_cpu_limits=3,\n",
    "    head_memory_requests=6,\n",
    "    head_memory_limits=6,\n",
    "    head_extended_resource_requests={'nvidia.com/gpu': 0},\n",
    "    worker_extended_resource_requests={'nvidia.com/gpu': 0},\n",
    "    num_workers=2,\n",
    "    worker_cpu_requests='1',  # Requesting 1 CPU per worker (this adds up to 5 CPUs total) -> now exceeding our adjusted quota.\n",
    "    worker_cpu_limits=1,\n",
    "    worker_memory_requests=4,\n",
    "    worker_memory_limits=6,\n",
    "    write_to_file=False,\n",
    "))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster2.up()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Verifying the Pending Workload\n",
    "Now that we have a second cluster competing for resources, let's check the `ClusterQueue` again by running:\n",
    "```\n",
    "oc get clusterqueue default -o yaml\n",
    "```\n",
    "In the resulting yaml, you should be able to observe the below output:\n",
    "```yaml\n",
    "  flavorsReservation:\n",
    "  - name: default\n",
    "    resources:\n",
    "    - borrowed: \"0\"\n",
    "      name: cpu\n",
    "      total: \"5\"\n",
    "    - borrowed: \"0\"\n",
    "      name: memory\n",
    "      total: 13671875Ki\n",
    "    - borrowed: \"0\"\n",
    "      name: nvidia.com/gpu\n",
    "      total: \"3\"\n",
    "  flavorsUsage:\n",
    "  - name: default\n",
    "    resources:\n",
    "    - borrowed: \"0\"\n",
    "      name: cpu\n",
    "      total: \"5\"\n",
    "    - borrowed: \"0\"\n",
    "      name: memory\n",
    "      total: 13671875Ki\n",
    "    - borrowed: \"0\"\n",
    "      name: nvidia.com/gpu\n",
    "      total: \"3\"\n",
    "  pendingWorkloads: 1\n",
    "  reservingWorkloads: 1\n",
    "```\n",
    "Here we can see that we have a workload pending and we can observe its requirements in `flavorsReservation`.\n",
    "We can verify this further by executing the below cell. The output should list the RayCluster as SUSPENDED."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster2.status()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's create a third RayCluster that requires signifantly fewer resource requirements. We can use this to demonstrate how Kueue allocates resources based on requirements when there is resource contention."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster_name_3 = \"kueue-ks-raycluster-3\"\n",
    "cluster3 = Cluster(ClusterConfiguration(\n",
    "    name=cluster_name_3,\n",
    "    head_cpu_requests='500m',\n",
    "    head_cpu_limits='500m',\n",
    "    head_memory_requests=2,\n",
    "    head_memory_limits=2,\n",
    "    head_extended_resource_requests={'nvidia.com/gpu':0}, # For GPU enabled workloads set the head_extended_resource_requests and worker_extended_resource_requests\n",
    "    worker_extended_resource_requests={'nvidia.com/gpu':0},\n",
    "    num_workers=2,\n",
    "    worker_cpu_requests='250m',\n",
    "    worker_cpu_limits=1,\n",
    "    worker_memory_requests=4,\n",
    "    worker_memory_limits=4,\n",
    "))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster3.up()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above cluster only requires 1 CPU per Head and Worker. This brings us to 7, 1 below our quota. Because of our `queueingStrategy` of `BestEffortFIFO` (which is set within the ClusterQueue spec), Kueue will priorise a workload that it has resources available for rather than waiting for the sufficient resources for RayCluster 2. This means that the above cluster will immediately served the resources it requires as its within our quota. We can check via oc as earlier using:\n",
    "```\n",
    "oc get clusterqueue default -o yaml\n",
    "```\n",
    "You should be able to observe the below:\n",
    "```yaml\n",
    "  flavorsUsage:\n",
    "  - name: default\n",
    "    resources:\n",
    "    - borrowed: \"0\"\n",
    "      name: cpu\n",
    "      total: \"6\"\n",
    "    - borrowed: \"0\"\n",
    "      name: memory\n",
    "      total: 23437500Ki\n",
    "    - borrowed: \"0\"\n",
    "      name: nvidia.com/gpu\n",
    "      total: \"3\"\n",
    "  pendingWorkloads: 1\n",
    "  reservingWorkloads: 2\n",
    "```\n",
    "\n",
    "The second cluster we created will still be pending but the others will have the requisite resources. We can also observe that our total cpu has risen to 7. We can finalize our verification by running the following command:\n",
    "```\n",
    "oc get rayclusters -n rhods-notebooks\n",
    "```\n",
    "You should see output similar to the below:\n",
    "```\n",
    "NAME                    DESIRED WORKERS   AVAILABLE WORKERS   CPUS   MEMORY   GPUS   STATUS      AGE\n",
    "kueue-ks-raycluster     2                 2                   5      14G      3      ready       87m\n",
    "kueue-ks-raycluster-2   2                                     5      14G      0      suspended   32m\n",
    "kueue-ks-raycluster-3   2                 2                   1      10G      0      ready       2m2s\n",
    "```\n",
    "We can now see that cluster 3 is ready and 2 is still suspended due to its greater resource requirements. We can verify this further by running the below cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster3.status()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cleanup\n",
    "Lets close this out by shutting down the 3 clusters we created."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster1.down()\n",
    "cluster2.down()\n",
    "cluster3.down()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "auth.logout()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.11",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
